{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #1\n",
    "#### Team Members: Arturo White, Conor Martin , Dean Thoms, Jackie Siegel, Nate Smith\n",
    "* Hypothesis:\n",
    "    - Teams perform better after a bye week\n",
    "        ○ The offense scores more points after a bye week\n",
    "        ○ The defense allows fewer points after a bye week\n",
    "\n",
    "    - Null hypothesis:\n",
    "        ○ Bye weeks have no impact on a team's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stat as st\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation:\n",
    "    1. Perform validations on each data source (i.e., Review team names to ensure consistency and review date format)\n",
    "        a. Kaggle (multiple)\n",
    "        b. CFB Stats (i.e., wins / losses / points)\n",
    "        c. Odd Shark (i.e., bye week data)\n",
    "    2. Join Kaggle tables together\n",
    "        a. Keys are going to verify per table\n",
    "        b. Refer to \"RELEASE.txt\" file for notes on columns\n",
    "            i. The \"Code\" columns allow you to tie the files together\n",
    "    3. Join Kaggle and CFB tables using a join key of:\n",
    "        a. Team Name\n",
    "        b. Date\n",
    "    4. Add Odd Shark data by joining on Date and Team Name; however, we want to populate a new column (i.e., \"Bye Week (Yes or No)\" in the data frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import consolidated Kaggle Game Stats files\n",
    "teamcodemaster = pd.read_csv('teamcodemaster.csv')\n",
    "kag09 = pd.read_csv('kag09')\n",
    "kag10 = pd.read_csv('kag10')\n",
    "kag11 = pd.read_csv('kag11')\n",
    "kag12 = pd.read_csv('kag12')\n",
    "kag13 = pd.read_csv('kag13')\n",
    "\n",
    "# Drop unnecessary \"Unnamed Columns\"\n",
    "kag09 = kag09.drop(['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 0'], axis=1)\n",
    "kag10 = kag10.drop(['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 0'], axis=1)\n",
    "kag11 = kag11.drop(['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 0'], axis=1)\n",
    "kag12 = kag12.drop(['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 0'], axis=1)\n",
    "kag13 = kag13.drop(['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# Convert \"Game Code\" columns to integer\n",
    "kag09['Game Code'] = kag09['Game Code'].astype('float').round(0)\n",
    "kag10['Game Code'] = kag10['Game Code'].astype('float').round(0)\n",
    "kag11['Game Code'] = kag11['Game Code'].astype('float').round(0)\n",
    "kag12['Game Code'] = kag12['Game Code'].astype('float').round(0)\n",
    "kag13['Game Code'] = kag13['Game Code'].astype('float').round(0)\n",
    "\n",
    "## Data quality checks\n",
    "#kaggle_df.count()\n",
    "# Display column names\n",
    "#for col in kaggle_df.columns: \n",
    "    #print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in all Game date data\n",
    "game_date09 = pd.read_csv('Game Dates_2009.csv')\n",
    "game_date10 = pd.read_csv('game date_2010.csv')\n",
    "game_date11 = pd.read_csv('game date_2011.csv')\n",
    "game_date12 = pd.read_csv('game date_2012.csv')\n",
    "game_date13 = pd.read_csv('Game Dates_2013.csv')\n",
    "\n",
    "# Merge all game date data\n",
    "#game_date_list_of_dfs = [game_date09, game_date10, game_date11, game_date12, game_date13]\n",
    "#game_date_df = pd.concat(game_date_list_of_dfs)\n",
    "#game_date_df.head()\n",
    "\n",
    "# Convert date from string to date type format\n",
    "game_date09['Date'] = pd.to_datetime(game_date09['Date'], errors = 'raise')\n",
    "game_date10['Date'] = pd.to_datetime(game_date10['Date'], errors = 'raise')\n",
    "game_date11['Date'] = pd.to_datetime(game_date11['Date'], errors = 'raise')\n",
    "game_date12['Date'] = pd.to_datetime(game_date12['Date'], errors = 'raise')\n",
    "game_date13['Date'] = pd.to_datetime(game_date13['Date'], errors = 'raise')\n",
    "\n",
    "# Convert \"Game Code\" columns to integer\n",
    "game_date09['Game Code'] = game_date09['Game Code'].astype('float').round(0)\n",
    "game_date10['Game Code'] = game_date10['Game Code'].astype('float').round(0)\n",
    "game_date11['Game Code'] = game_date11['Game Code'].astype('float').round(0)\n",
    "game_date12['Game Code'] = game_date12['Game Code'].astype('float').round(0)\n",
    "game_date13['Game Code'] = game_date13['Game Code'].astype('float').round(0)\n",
    "\n",
    "#game_dates = pd.concat([game_date09, game_date10, game_date11, game_date12, game_date13])\n",
    "#game_dates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ecah of the game dates by year\n",
    "kag09_conf = pd.merge(kag09, game_date09, how = 'left', on = 'Game Code')\n",
    "kag10_conf = pd.merge(kag10, game_date10, how = 'left', on = 'Game Code')\n",
    "kag11_conf = pd.merge(kag11, game_date11, how = 'left', on = 'Game Code')\n",
    "kag12_conf = pd.merge(kag12, game_date12, how = 'left', on = 'Game Code')\n",
    "kag13_conf = pd.merge(kag13, game_date13, how = 'left', on = 'Game Code')\n",
    "\n",
    "# Merge all kaggle data\n",
    "kaggle_list_of_dfs = [kag09_conf, kag10_conf, kag11_conf, kag12_conf, kag13_conf]\n",
    "kaggle_df = pd.concat(kaggle_list_of_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in Conferce names to DF\n",
    "\n",
    "## Import data\n",
    "conf_name_df = pd.read_csv('conference11.csv')\n",
    "conf_name_df.head()\n",
    "\n",
    "## Merge data\n",
    "kaggle_conf_df = pd.merge(kaggle_df, conf_name_df, on = 'Conference Code', how = 'left')\n",
    "\n",
    "# Rename columns that received a _x suffix\n",
    "kaggle_conf_df = kaggle_conf_df.rename(columns={'Name_x': 'Name', 'Name_y': 'Conference Name', 'Subdivision_x': 'Subdivision'})\n",
    "\n",
    "#for col in kaggle_df.columns: \n",
    "    #print(col) \n",
    "\n",
    "# Data quality checks\n",
    "#kaggle_conf_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in Odd Shark data\n",
    "odd_shark = pd.read_csv('teamcodemaster____Nate Edited.csv')\n",
    "\n",
    "# Print columns to check quality\n",
    "#for col in odd_shark.columns: \n",
    "    #print(col) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the Odd Shark data to the Kaggle stats data\n",
    "temp_combined_df_1 = pd.merge(kaggle_conf_df, odd_shark, how = 'left', on = 'Name')\n",
    "\n",
    "# Join the game date data to the temp combined df\n",
    "### This is what will need to be deleted\n",
    "#temp_combined_df_2 = pd.merge(temp_combined_df_1, game_date_df, how = 'left', on = 'Game Code')\n",
    "    \n",
    "# Drop unnecessary columns\n",
    "temp_combined_df_1 = temp_combined_df_1.drop(['Team Code_y', 'Conference Code_y'], axis=1)\n",
    "\n",
    "# Rename columns that received a _x suffix\n",
    "temp_combined_df_1 = temp_combined_df_1.rename(columns={'Team Code_x': 'Team Code', 'Conference Code_x': 'Conference Code'})\n",
    "\n",
    "# Convert all \"Unnamed: X\" columns to date format\n",
    "temp_combined_df_1['Unnamed: 3'] = pd.to_datetime(temp_combined_df_1['Unnamed: 3'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 4'] = pd.to_datetime(temp_combined_df_1['Unnamed: 4'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 5'] = pd.to_datetime(temp_combined_df_1['Unnamed: 5'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 6'] = pd.to_datetime(temp_combined_df_1['Unnamed: 6'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 7'] = pd.to_datetime(temp_combined_df_1['Unnamed: 7'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 8'] = pd.to_datetime(temp_combined_df_1['Unnamed: 8'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 9'] = pd.to_datetime(temp_combined_df_1['Unnamed: 9'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 10'] = pd.to_datetime(temp_combined_df_1['Unnamed: 10'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 11'] = pd.to_datetime(temp_combined_df_1['Unnamed: 11'], errors = 'raise')\n",
    "temp_combined_df_1['Unnamed: 12'] = pd.to_datetime(temp_combined_df_1['Unnamed: 12'], errors = 'raise')\n",
    "\n",
    "# Add empty column 'bye' to store if the game was after a bye week or not\n",
    "temp_combined_df_1['bye'] = np.nan\n",
    "\n",
    "# Print all column names of temp_combined_df_1\n",
    "#for col in temp_combined_df_2.columns: \n",
    "    #print(col) \n",
    "    \n",
    "# Data quality checks\n",
    "#temp_combined_df_1.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate 'bye' column with an x if the game was after a bye week\n",
    "## Create a loop that goes through the various bye week columns\n",
    "for row in range(0, len(temp_combined_df_1)):\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 3']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 4']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 5']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 6']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 7']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 8']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 9']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 10']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 11']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "    if temp_combined_df_1.loc[row,'Date'] == temp_combined_df_1.loc[row, 'Unnamed: 12']:\n",
    "        temp_combined_df_1.loc[row,'bye'] = 'x'\n",
    "\n",
    "# Count the total number of games after the bye week\n",
    "#temp_combined_df_2[temp_combined_df_2.bye == 'x'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Unnamed Columns\" from the temp data frame\n",
    "## We no longer need these now that we have successfully populated the 'bye' week column\n",
    "temp_clean_df = temp_combined_df_1.drop(['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12'], axis=1)\n",
    "\n",
    "# Convert date from string to date type format\n",
    "temp_clean_df['New Date'] = pd.to_datetime(temp_clean_df['Date'])\n",
    "    \n",
    "# Data quality checks\n",
    "# temp_clean_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the points for, points against, and win vs. loss information from CFB Stats\n",
    "\n",
    "# 2009 Data\n",
    "wl2009 = pd.read_csv('WL2009 Clean.csv')\n",
    "wl2009 = wl2009.rename(columns={'Pts': 'Winner Points', 'Pts.1': 'Loser Points'})\n",
    "wl2009['New Date'] = pd.to_datetime(wl2009['Date'])\n",
    "wl2009 = wl2009.drop_duplicates(['Date', 'Winner', 'Winner Points', 'Loser', 'Loser Points'])\n",
    "\n",
    "# 2010 Data\n",
    "wl2010 = pd.read_excel('WL2010Clean.xlsx')\n",
    "wl2010 = wl2010.rename(columns={'Pts': 'Winner Points', 'Pts.1': 'Loser Points'})\n",
    "wl2010['New Date'] = pd.to_datetime(wl2010['Date'])\n",
    "wl2010 = wl2010.drop_duplicates(['Date', 'Winner', 'Winner Points', 'Loser', 'Loser Points'])\n",
    "\n",
    "# 2011 Data\n",
    "wl2011 = pd.read_excel('WL2011_Cleaned_edited7_27_19.xlsx')\n",
    "wl2011 = wl2011.rename(columns={'Pts': 'Winner Points', 'Pts.1': 'Loser Points'})\n",
    "wl2011['New Date'] = pd.to_datetime(wl2011['Date'])\n",
    "wl2011 = wl2011.drop_duplicates(['Date', 'Winner', 'Winner Points', 'Loser', 'Loser Points'])\n",
    "\n",
    "# 2012 Data\n",
    "wl2012 = pd.read_csv('WL2012CLEAN.csv')\n",
    "wl2012 = wl2012.rename(columns={'Pts': 'Winner Points', 'Pts.1': 'Loser Points'})\n",
    "wl2012['New Date'] = pd.to_datetime(wl2012['Date'])\n",
    "wl2012 = wl2012.drop_duplicates(['Date', 'Winner', 'Winner Points', 'Loser', 'Loser Points'])\n",
    "\n",
    "# 2013 Data\n",
    "wl2013 = pd.read_csv('WL2013CLEAN.csv')\n",
    "wl2013 = wl2013.rename(columns={'Pts': 'Winner Points', 'Pts.1': 'Loser Points'})\n",
    "wl2013['New Date'] = pd.to_datetime(wl2013['Date'])\n",
    "wl2013 = wl2013.drop_duplicates(['Date', 'Winner', 'Winner Points', 'Loser', 'Loser Points'])\n",
    "\n",
    "# Merge all W/L and Points data\n",
    "points_list_of_dfs = [wl2009, wl2010, wl2011, wl2012, wl2013]\n",
    "point_df = pd.concat(points_list_of_dfs, sort = 'True')\n",
    "\n",
    "# Data quality tests\n",
    "#point_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Munging:\n",
    "    1. Check for any NaN values or null records in critical fields\n",
    "    2. Remove any unnecessary teams from the data frame\n",
    "    3. Disaggregate data frame into two sub components\n",
    "        a. Create data frame that only contains the game information after bye week\n",
    "            i. EX: bye_week_df = df[df['Bye Week (Yes or No)'] == \"Yes\"]\u000b",
    "Create data frame that contains all but the games after bye week\n",
    "            ii. EX: bye_week_df = df[df['Bye Week (Yes or No)'] == \"No\"]\n",
    "    4. Separate dataframes by year (**Note this isn't 100% necessary as we could always group-by year and team name later, but I think separating the dataframes will make it easier on us)\n",
    "\n",
    "### Analysis Prep:\n",
    "    1. Group each df by team name\n",
    "    2. Calculate the mean of each critical field for non-bye week dataframes (i.e., mean of total points, off. Points, etc.)\n",
    "        a. Note I will be referring to these data frames as \"Grouped by Team Non-Bye Week df\" for the remainder of this pseudocode\n",
    "    3. Join in the \"Bye Week Stats df\" (i.e., the bye week data frame grouped by team name) into the \"Grouped by Team Non-Bye Week df\"\n",
    "        a. Note that the \"Grouped by Team Non-Bye Week df\" should be the left portion of the join\n",
    "        b. Add prefix to all right side of join columns to easily distinguish that those are the by week stats\n",
    "    4. Remove unnecessary columns for ease of workability (i.e., create offense only df, defense only df, total points df, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge the points for, points against, and win vs. loss information from CFB Stats into temp data frame\n",
    "\n",
    "## Merge based on the winner\n",
    "consolidated_df_v0 = pd.merge(temp_clean_df, point_df, how = 'left', left_on = ['Name', 'New Date'], right_on = ['Winner', 'New Date'])\n",
    "# Rename _x suffix\n",
    "consolidated_df_v0 = consolidated_df_v0.rename(columns={'Date_x': 'Date'})\n",
    "# Drop unnecessary repeated columns (i.e., \"Date_y\")\n",
    "consolidated_df_v0 = consolidated_df_v0.drop(['Date_y'], axis=1)\n",
    "\n",
    "## Merge based on the loser\n",
    "consolidated_df = pd.merge(consolidated_df_v0, point_df, how = 'left', left_on = ['Name', 'New Date'], right_on = ['Loser', 'New Date'])\n",
    "# Rename _x suffix\n",
    "consolidated_df = consolidated_df.rename(columns={'Date_x': 'Date'})\n",
    "# Drop unnecessary repeated columns (i.e., \"Date_y\")\n",
    "consolidated_df = consolidated_df.drop(['Date_y'], axis=1)\n",
    "\n",
    "# Data quality checks\n",
    "#consolidated_df.count()\n",
    "\n",
    "# Print all column names of consolidated_df\n",
    "#for col in consolidated_df.columns: \n",
    "    #print(col) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify if record was a Win or Loss\n",
    "\n",
    "## add outcome column to store win / loss\n",
    "consolidated_df['outcome'] = ''\n",
    "## Loop through data set and add win / loss to each record\n",
    "for row in range(0, len(consolidated_df)):\n",
    "    if consolidated_df.loc[row,'Winner_x'] == consolidated_df.loc[row,'Name']:\n",
    "        consolidated_df.loc[row,'outcome'] = 'Win'\n",
    "    else:\n",
    "        consolidated_df.loc[row,'outcome'] = 'Loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and implement a points for and points against column\n",
    "\n",
    "## add points for and against columns to store data\n",
    "consolidated_df['points_for'] = ''\n",
    "consolidated_df['points_against'] = ''\n",
    "\n",
    "## Loop through data set and add win / loss to each record\n",
    "for row in range(0, len(consolidated_df)):\n",
    "    if consolidated_df.loc[row,'outcome'] == 'Win':\n",
    "        consolidated_df.loc[row,'points_for'] = consolidated_df.loc[row,'Winner Points_x']\n",
    "    else:\n",
    "        consolidated_df.loc[row,'points_for'] = consolidated_df.loc[row,'Loser Points_y']\n",
    "    if consolidated_df.loc[row,'outcome'] == 'Win':\n",
    "        consolidated_df.loc[row,'points_against'] = consolidated_df.loc[row,'Loser Points_x']\n",
    "    else:\n",
    "        consolidated_df.loc[row,'points_against'] = consolidated_df.loc[row,'Winner Points_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all unnecessary columns from consolidated df\n",
    "\n",
    "# Rename _x suffix\n",
    "#consolidated_df = consolidated_df.rename(columns={'Date_x': 'Date'})\n",
    "drop_columns = ['Day_x', 'Winner_x', 'Winner Points_x', 'Loser_x', 'Loser Points_x', 'Day_y', 'Winner_y', 'Winner Points_y', 'Loser_y', 'Loser Points_y']\n",
    "# Drop unnecessary repeated columns (i.e., \"Date_y\")\n",
    "consolidated_df = consolidated_df.drop(drop_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Code</th>\n",
       "      <th>Game Code</th>\n",
       "      <th>Rush Att</th>\n",
       "      <th>Rush Yard</th>\n",
       "      <th>Rush TD</th>\n",
       "      <th>Pass Att</th>\n",
       "      <th>Pass Comp</th>\n",
       "      <th>Pass Yard</th>\n",
       "      <th>Pass TD</th>\n",
       "      <th>Pass Int</th>\n",
       "      <th>...</th>\n",
       "      <th>Stadium Code</th>\n",
       "      <th>Site</th>\n",
       "      <th>Conference Name</th>\n",
       "      <th>Subdivision</th>\n",
       "      <th>New Date</th>\n",
       "      <th>Wk_x</th>\n",
       "      <th>Wk_y</th>\n",
       "      <th>outcome</th>\n",
       "      <th>points_for</th>\n",
       "      <th>points_against</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bye</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>...</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>404</td>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team Code  Game Code  Rush Att  Rush Yard  Rush TD  Pass Att  Pass Comp  \\\n",
       "bye                                                                            \n",
       "x          404        404       404        404      404       404        404   \n",
       "\n",
       "     Pass Yard  Pass TD  Pass Int  ...  Stadium Code  Site  Conference Name  \\\n",
       "bye                                ...                                        \n",
       "x          404      404       404  ...           404   404              404   \n",
       "\n",
       "     Subdivision  New Date  Wk_x  Wk_y  outcome  points_for  points_against  \n",
       "bye                                                                          \n",
       "x            404       404    22    26      404         379             379  \n",
       "\n",
       "[1 rows x 83 columns]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_df.to_csv('df.csv')\n",
    "consolidated_df.groupby('bye').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis / Statistical Results:\n",
    "    1. Perform ANOVA analysis on respective fields from mean season vs. after bye week\n",
    "        a. Determine if there is significance between the data\n",
    "    2. T-test to see if there is statistical significance b/n post bye week performance compared to avg. performance\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization:\n",
    "    1. Box and Whisker plot of statistical results\n",
    "    2. Create clustered bar chart for each of the major comparisons:\n",
    "        a. Win % over the five years (each cluster of bars is a team)\n",
    "        b. Avg Off. Pts. Over the five years (each cluster of bars is a team)\n",
    "        c. Avg Def. Pts Allowed Over the five years (each cluster of bars is a team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 36 (PythonData36)",
   "language": "python",
   "name": "pythondata36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
